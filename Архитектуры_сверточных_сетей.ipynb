{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Задание\n",
        "Проведите эксперименты по начальному обучению различных моделей и сравните результаты.\n",
        "\n",
        "Возьмите датасет EMNIST из torchvision.  \n",
        "Обучите на нём модели: ResNet 18, VGG 16, Inception v3, DenseNet 161:\n",
        "желательно обучить каждую модель с нуля по 10 эпох   \n",
        "если ресурсов компьютера / Colab не хватает, достаточно обучить каждую модель по 1-2 эпохи  \n",
        "Сведите результаты обучения моделей (графики лосса) в таблицу и сравните их.   \n",
        "\n",
        "#### Инструкция к выполнению задания\n",
        "\n",
        "1. Загрузите датасет, посмотрите примеры картинок в нём и проверьте наличествующие классы и их дисбаланс.\n",
        "2. Создайте модель текущего типа, используя интерфейс torchvision для нужного количества классов.\n",
        "3. Обучите модель с нуля до 1-10 эпох — количество эпох выбираете сами в зависимости от вычислительных ресурсов. Фиксируйте значение функции потерь в список для последующего отображения.\n",
        "4. Повторите пункты 2 и 3 для всех указанных вариантов моделей."
      ],
      "metadata": {
        "id": "RNFgJvC4X-hi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "CWySkE_EX9m7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision as tv\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchsummary import summary\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "data_train = datasets.EMNIST('.', split ='balanced', download = True, train = True, transform = transform)\n",
        "data_test = datasets.EMNIST('.', split ='balanced', download = True, train = False, transform = transform)"
      ],
      "metadata": {
        "id": "P9ZpGv7eYC5g"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindata = DataLoader(data_train, batch_size = 100, shuffle = True)\n",
        "testdata = DataLoader(data_test, batch_size = 100, shuffle = True)"
      ],
      "metadata": {
        "id": "mhKApgYuYJmA"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(traindata)\n",
        "data = next(dataiter)\n",
        "features, labels = data"
      ],
      "metadata": {
        "id": "QpXCi3j7YMDj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Размер изображения', features[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HXRVoG8YOsQ",
        "outputId": "0c85c6eb-2aba-4097-ca06-ec7ff34b2f4d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер изображения torch.Size([1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(torch.squeeze(features[0]), cmap = 'gray')\n",
        "plt.title('Класс '+ str(labels[0].item()))\n",
        "plt.show()\n",
        "plt.imshow(torch.squeeze(features[40]), cmap = 'gray')\n",
        "plt.title('Класс '+ str(labels[40].item()))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "dz5-bfiVYQDy",
        "outputId": "3ee7e245-cba3-4abe-8778-4621de4aa4fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjK0lEQVR4nO3de3SU9Z3H8c8khAloMhgCucgdRNaCWFmSUkqkNQtBj8ttPSq0hV1Xjja4Iou62V1F6bbp6pba9lAve1xia9GudoGF1mDAJmxbwHJbpO5Sk8YSDyQomplwC5j89g+WqSMJ+BuSfHN5v875ncM8z+87883jYz55Zp78EnDOOQEA0MESrBsAAPRMBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAGEHqmkpESBQEA7d+48b9+//uu/KhAIaNasWWpqajLorm00NjbqoYceUnZ2tvr06aPc3FyVlZVZtwVEEUDAx6xdu1b33HOPpkyZopdeekmJiYnWLcVt4cKFWrlypebPn6/vfve7SkxM1E033aRf/vKX1q0BkqRe1g0AnUV5ebnuuOMOXXPNNdqwYYOSk5OtW4rbG2+8oZdeeklPPPGEli1bJkn66le/qrFjx+rBBx/Ur3/9a+MOAa6AAEnS3r17NXPmTGVlZWnTpk0KhULnzXnnnXcUCARaHB/3L//yL/r85z+v/v37q0+fPpowYYJeeeWVFl/3hRdeUE5Ojvr27asrrrhCeXl5eu2112LmvPrqq7rhhhuUkpKi1NRUTZw4UWvWrLng1/PKK68oMTFRixYtim5LTk7WnXfeqW3btqmmpubTHhqg3RBA6PGqqqpUUFCgYDCoTZs2KSsr64LzFy1apB/96Ef60Y9+pNmzZ5+3/7vf/a4++9nPasWKFfrmN7+pXr166dZbb9XPfvazmHmPPfaYvvKVrygpKUkrVqzQY489psGDB+v111+PzikpKdHNN9+sDz74QEVFRfrWt76l6667TqWlpRfscc+ePRo9erRSU1Njtufk5Eg6G7iANd6CQ49WV1en22+/XXV1dZo2bZpGjx7d6tyPPvpIkjR58mR9+ctfliRVVlZq7dq1MfN+97vfqU+fPtHHixcv1vXXX6+VK1fq5ptvjtatWLFCs2fP1iuvvKKEhD/+LHjuT3SFw2H9zd/8jXJyclReXh7zluDF/ozX4cOHWwzSc9sOHTp0wXqgI3AFhB5t4cKFqqmp0bx58/Taa6/p5ZdfbnXu6dOnJUnBYPCCz/nx8Pnwww8VDoc1ZcoU7d69O7p93bp1am5u1iOPPBITPpKib+mVlZWpoaFBf/d3f3fe51GffNvvk06ePNlin+ee5+TJkxesBzoCAYQe7YMPPtALL7yg559/Xtddd53uu+8+hcPhFufW19dLki6//PILPufGjRv1uc99TsnJyUpLS9OAAQP01FNPxTxvVVWVEhISdM0117T6PFVVVZKksWPHen5VZ0OwsbHxvO2nTp2K7gesEUDo0Z544gndeuut6tWrl5599lnV1dWpqKioxbm1tbWSpMzMzFaf77/+67/053/+50pOTtYPfvAD/fznP1dZWZnmzZt30bfN2lJWVpYOHz583vZz27KzszusF6A1BBB6tLy8vOi/J06cqMLCQj3zzDPavn37eXPfeustBQIBXX311a0+309/+lMlJydr06ZN+qu/+ivNmDFD+fn5580bOXKkmpub9dZbb7X6XCNHjpQk7d+/3+dLkiRdd911+t3vfqdIJBKzfceOHdH9gDUCCPiYb3zjG8rKytKiRYuiNx1IZ29A+OlPf6qcnJwLvgWXmJioQCAQs4LCO++8o3Xr1sXMmzVrlhISErRixQo1NzfH7Dt3pTRt2jSlpKSouLg4+tbZJ+e05i/+4i/U1NSkZ599NrqtsbFRq1evVm5urgYPHnzBeqAjcBcc8DEpKSn6/ve/rzlz5ujb3/62HnroIW3evFkPP/yw9u3bpw0bNlyw/uabb9bKlStVUFCgefPm6ciRI1q1apVGjRqlffv2ReeNGjVK//AP/6Cvf/3rmjJliubMmaNgMKjf/OY3ys7OVnFxsVJTU/Wd73xHf/3Xf62JEydq3rx5uuKKK/Tf//3fOnHihJ5//vlW+8jNzdWtt96qoqIiHTlyRKNGjdLzzz+vd955R88991ybHS/gkjigB1q9erWT5H7zm9+0uH/mzJmub9++7ve//7279957XV5enistLT1v3vLly90n/zd67rnn3FVXXeWCwaAbM2aMW716dYvznHPu3/7t39xnP/tZFwwG3RVXXOFuuOEGV1ZWFjPnP//zP93nP/9516dPH5eamupycnLciy++eNGv8eTJk27ZsmUuMzPTBYNBN3HixBa/BsBKwLkO/GQUAID/x2dAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMBEp/tF1ObmZh06dEgpKSkXXfEXAND5OOfU0NCg7Ozs81Z7/7hOF0CHDh1imRAA6AZqamo0aNCgVvd3urfgUlJSrFsAALSBi30/b7cAWrVqlYYNG6bk5GTl5ubqjTfe+FR1vO0GAN3Dxb6ft0sA/eQnP9HSpUu1fPly7d69W+PHj9f06dN15MiR9ng5AEBX1B4LzOXk5LjCwsLo46amJpedne2Ki4svWhsOh50kBoPBYHTxEQ6HL/j9vs2vgE6fPq1du3bF/BGuhIQE5efna9u2befNb2xsVCQSiRkAgO6vzQPo/fffV1NTkzIyMmK2Z2RkRP+k8ccVFxcrFApFB3fAAUDPYH4XXFFRkcLhcHTU1NRYtwQA6ABt/ntA6enpSkxMVF1dXcz2uro6ZWZmnjc/GAwqGAy2dRsAgE6uza+AevfurQkTJmjLli3Rbc3NzdqyZYsmTZrU1i8HAOii2mUlhKVLl2rBggX60z/9U+Xk5OjJJ5/U8ePH9Zd/+Zft8XIAgC6oXQLotttu03vvvadHHnlEtbW1uu6661RaWnrejQkAgJ4r4Jxz1k18XCQSUSgUsm4DAHCJwuGwUlNTW91vfhccAKBnIoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgIk2D6BHH31UgUAgZowZM6atXwYA0MX1ao8n/cxnPqPNmzf/8UV6tcvLAAC6sHZJhl69eikzM7M9nhoA0E20y2dAb7/9trKzszVixAjNnz9fBw8ebHVuY2OjIpFIzAAAdH9tHkC5ubkqKSlRaWmpnnrqKVVXV2vKlClqaGhocX5xcbFCoVB0DB48uK1bAgB0QgHnnGvPF6ivr9fQoUO1cuVK3Xnnneftb2xsVGNjY/RxJBIhhACgGwiHw0pNTW11f7vfHdCvXz+NHj1alZWVLe4PBoMKBoPt3QYAoJNp998DOnbsmKqqqpSVldXeLwUA6ELaPICWLVumiooKvfPOO/r1r3+t2bNnKzExUXfccUdbvxQAoAtr87fg3n33Xd1xxx06evSoBgwYoC984Qvavn27BgwY0NYvBQDowtr9JgRfkUhEoVDIug3gU4vnF62TkpK8azIyMrxruuMvgYfDYe+aDz/8sB06aVlzc3OH1HQFF7sJgbXgAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmOh+KxUCkhITE+OqGzp0qHfNzJkzvWsGDRrkXXPDDTd416SkpHjXdKR4FuH87W9/613z5ptvetdIUjxrNe/Zs8e7pqyszLvm1KlT3jWdDVdAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATARfPcq/tKBKJKBQKWbeBdhIMBr1rrrzySu+a66+/3rtGkubPn+9dk5+f713Tu3dv75qEBP+fF+NZbVqS6uvrvWvC4bB3TTzffuL5/pCWluZdI8XX38GDB71rHn30Ue+aV155xbtGkhobG+Oqi0c4HFZqamqr+7kCAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYKKXdQOwl56eHlfdsGHDvGvuu+8+75pZs2Z51yQnJ3vXSNLRo0e9a0pLS71rNmzY4F3T0NDgXfPb3/7Wu0aSPvzwQ++aeBYwjcfgwYO9a772ta/F9Vpz5871rhk5cqR3zbe//W3vmhMnTnjXSNL69eu9a+Jd1PZiuAICAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggsVIu5levfz/k37zm9+M67W+9KUveddkZGR41yQk+P+ctH//fu8aSXryySe9a1599VXvmngWPXXOede01yKSln7/+99716xYsSKu10pMTPSuWbx4sXdNWlqad824ceO8a6T4FsJlMVIAQLdCAAEATHgH0NatW3XLLbcoOztbgUBA69ati9nvnNMjjzyirKws9enTR/n5+Xr77bfbql8AQDfhHUDHjx/X+PHjtWrVqhb3P/744/re976np59+Wjt27NBll12m6dOn69SpU5fcLACg+/D+xHrGjBmaMWNGi/ucc3ryySf1j//4j5o5c6Yk6Yc//KEyMjK0bt063X777ZfWLQCg22jTz4Cqq6tVW1ur/Pz86LZQKKTc3Fxt27atxZrGxkZFIpGYAQDo/to0gGprayWdf6ttRkZGdN8nFRcXKxQKRUc8f+8dAND1mN8FV1RUpHA4HB01NTXWLQEAOkCbBlBmZqYkqa6uLmZ7XV1ddN8nBYNBpaamxgwAQPfXpgE0fPhwZWZmasuWLdFtkUhEO3bs0KRJk9rypQAAXZz3XXDHjh1TZWVl9HF1dbX27t2rtLQ0DRkyREuWLNE//dM/6aqrrtLw4cP18MMPKzs7W7NmzWrLvgEAXZx3AO3cuVNf/OIXo4+XLl0qSVqwYIFKSkr04IMP6vjx41q0aJHq6+v1hS98QaWlpUpOTm67rgEAXZ53AE2dOvWCiyIGAgGtWLEi7sX/8EfxhHZBQYF3zS233OJdI539pWRfzz77rHfNu+++613z8beBfRw4cMC7prGxMa7XQseJ9wfgIUOGeNcEAgHvmngWmu0OzO+CAwD0TAQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE96rYSM+wWDQu2bu3LneNY8++qh3zf79+71rJGnVqlXeNWVlZd418aw2/dFHH3nXoPuaMmVKXHWTJ0/2rklMTPSuef/9971r3nzzTe8aSWpubo6rrj1wBQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEi5HGIRAIeNeMGTPGu2bZsmXeNZmZmd41DzzwgHeNJG3cuNG7hkVCcan69u3rXfPlL385rtdKT0/3rjl58qR3zauvvupd86tf/cq7RmIxUgAACCAAgA0CCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmGAx0jgMGDDAu2bJkiXeNaNGjfKu2bx5s3fNpk2bvGskFhZFrHgW6R06dKh3zYIFC7xrpk+f7l0jxbdwZzz/P33jG9/wrnnvvfe8azobroAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCY6NGLkQaDwbjqZsyY0SE1dXV13jUlJSXeNSdPnvSuQdcQzwKhktS/f3/vmmHDhnnX3Hfffd41s2bN8q45dOiQd40k7d6927vmmWee8a6prq72rnHOedd0NlwBAQBMEEAAABPeAbR161bdcsstys7OViAQ0Lp162L2L1y4UIFAIGYUFBS0Vb8AgG7CO4COHz+u8ePHa9WqVa3OKSgo0OHDh6PjxRdfvKQmAQDdj/dNCDNmzLjoB+rBYFCZmZlxNwUA6P7a5TOg8vJyDRw4UFdffbXuueceHT16tNW5jY2NikQiMQMA0P21eQAVFBTohz/8obZs2aJ//ud/VkVFhWbMmKGmpqYW5xcXFysUCkXH4MGD27olAEAn1Oa/B3T77bdH/z1u3Dhde+21GjlypMrLy3XjjTeeN7+oqEhLly6NPo5EIoQQAPQA7X4b9ogRI5Senq7KysoW9weDQaWmpsYMAED31+4B9O677+ro0aPKyspq75cCAHQh3m/BHTt2LOZqprq6Wnv37lVaWprS0tL02GOPae7cucrMzFRVVZUefPBBjRo1StOnT2/TxgEAXZt3AO3cuVNf/OIXo4/PfX6zYMECPfXUU9q3b5+ef/551dfXKzs7W9OmTdPXv/71uNddAwB0T94BNHXq1Asugrdp06ZLaqgjxfu2YGFhoXfNZZdd5l3z9NNPe9eUlZV516Dj9erlf/9PUlKSd83o0aO9ayRpyZIl3jVTpkzxrsnIyPCuqa2t9a654447vGsk6Q9/+IN3zYV+7aQ1zc3N3jXdAWvBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMtPmf5O5K0tLS4qpLT0/3rnnvvfe8azZs2OBdc+LECe8a/FFiYqJ3Tf/+/b1r5s+f711z5ZVXetf82Z/9mXeNdPYvGfuqq6vzrolnxfetW7d61+zatcu7RtIFV/7HpeMKCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgIlusxhpPItITpgwIa7XimcR0w8++MC7JhAIeNckJSV518SrX79+3jWhUKjtG2lBPOeDJI0bN8675rbbbvOuuemmm7xrevfu7V1z+vRp7xpJeu2117xrSkpKvGs2b97sXXPy5EnvGhYV7Zy4AgIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGAi4DrZKn2RSKTDFqwcNmxYXHWrV6/2rsnNzfWuOXbsmHdNfX29d0284vnvlJKS4l0Tzyn60UcfeddI0nvvvedd09TU5F3z5ptvdkjN7t27vWukjlskFN1bOBxWampqq/u5AgIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCiRy9GmpSUFFfdNddc412zZMkS75rPfe5z3jUJCR33M0VDQ4N3TUVFhXdNJBLpkBpJ2rp1q3dNOBzukJp4FpqNZ6FUSWpubo6rDvg4FiMFAHRKBBAAwIRXABUXF2vixIlKSUnRwIEDNWvWLB04cCBmzqlTp1RYWKj+/fvr8ssv19y5c1VXV9emTQMAuj6vAKqoqFBhYaG2b9+usrIynTlzRtOmTdPx48ejc+6//35t2LBBL7/8sioqKnTo0CHNmTOnzRsHAHRtvXwml5aWxjwuKSnRwIEDtWvXLuXl5SkcDuu5557TmjVr9KUvfUnS2b8e+id/8ifavn17XB+qAwC6p0v6DOjcnTxpaWmSpF27dunMmTPKz8+PzhkzZoyGDBmibdu2tfgcjY2NikQiMQMA0P3FHUDNzc1asmSJJk+erLFjx0qSamtr1bt3b/Xr1y9mbkZGhmpra1t8nuLiYoVCoegYPHhwvC0BALqQuAOosLBQ+/fv10svvXRJDRQVFSkcDkdHTU3NJT0fAKBr8PoM6JzFixdr48aN2rp1qwYNGhTdnpmZqdOnT6u+vj7mKqiurk6ZmZktPlcwGFQwGIynDQBAF+Z1BeSc0+LFi7V27Vq9/vrrGj58eMz+CRMmKCkpSVu2bIluO3DggA4ePKhJkya1TccAgG7B6wqosLBQa9as0fr165WSkhL9XCcUCqlPnz4KhUK68847tXTpUqWlpSk1NVX33nuvJk2axB1wAIAYXgH01FNPSZKmTp0as3316tVauHChJOk73/mOEhISNHfuXDU2Nmr69On6wQ9+0CbNAgC6jx69GGm8AoGAd03//v29az55N2Fn89FHH3nXxLMqxpkzZ7xr4hXP1wSgZSxGCgDolAggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJuL6i6g9XTwLiL///vsdUgMAXQVXQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABNeAVRcXKyJEycqJSVFAwcO1KxZs3TgwIGYOVOnTlUgEIgZd999d5s2DQDo+rwCqKKiQoWFhdq+fbvKysp05swZTZs2TcePH4+Zd9ddd+nw4cPR8fjjj7dp0wCArq+Xz+TS0tKYxyUlJRo4cKB27dqlvLy86Pa+ffsqMzOzbToEAHRLl/QZUDgcliSlpaXFbP/xj3+s9PR0jR07VkVFRTpx4kSrz9HY2KhIJBIzAAA9gItTU1OTu/nmm93kyZNjtj/zzDOutLTU7du3z73wwgvuyiuvdLNnz271eZYvX+4kMRgMBqObjXA4fMEciTuA7r77bjd06FBXU1NzwXlbtmxxklxlZWWL+0+dOuXC4XB01NTUmB80BoPBYFz6uFgAeX0GdM7ixYu1ceNGbd26VYMGDbrg3NzcXElSZWWlRo4ced7+YDCoYDAYTxsAgC7MK4Ccc7r33nu1du1alZeXa/jw4Ret2bt3ryQpKysrrgYBAN2TVwAVFhZqzZo1Wr9+vVJSUlRbWytJCoVC6tOnj6qqqrRmzRrddNNN6t+/v/bt26f7779feXl5uvbaa9vlCwAAdFE+n/uolff5Vq9e7Zxz7uDBgy4vL8+lpaW5YDDoRo0a5R544IGLvg/4ceFw2Px9SwaDwWBc+rjY9/7A/wdLpxGJRBQKhazbAABconA4rNTU1Fb3sxYcAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMBEpwsg55x1CwCANnCx7+edLoAaGhqsWwAAtIGLfT8PuE52ydHc3KxDhw4pJSVFgUAgZl8kEtHgwYNVU1Oj1NRUow7tcRzO4jicxXE4i+NwVmc4Ds45NTQ0KDs7WwkJrV/n9OrAnj6VhIQEDRo06IJzUlNTe/QJdg7H4SyOw1kch7M4DmdZH4dQKHTROZ3uLTgAQM9AAAEATHSpAAoGg1q+fLmCwaB1K6Y4DmdxHM7iOJzFcTirKx2HTncTAgCgZ+hSV0AAgO6DAAIAmCCAAAAmCCAAgAkCCABgossE0KpVqzRs2DAlJycrNzdXb7zxhnVLHe7RRx9VIBCIGWPGjLFuq91t3bpVt9xyi7KzsxUIBLRu3bqY/c45PfLII8rKylKfPn2Un5+vt99+26bZdnSx47Bw4cLzzo+CggKbZttJcXGxJk6cqJSUFA0cOFCzZs3SgQMHYuacOnVKhYWF6t+/vy6//HLNnTtXdXV1Rh23j09zHKZOnXre+XD33XcbddyyLhFAP/nJT7R06VItX75cu3fv1vjx4zV9+nQdOXLEurUO95nPfEaHDx+Ojl/+8pfWLbW748ePa/z48Vq1alWL+x9//HF973vf09NPP60dO3bosssu0/Tp03Xq1KkO7rR9Xew4SFJBQUHM+fHiiy92YIftr6KiQoWFhdq+fbvKysp05swZTZs2TcePH4/Ouf/++7Vhwwa9/PLLqqio0KFDhzRnzhzDrtvepzkOknTXXXfFnA+PP/64UcetcF1ATk6OKywsjD5uampy2dnZrri42LCrjrd8+XI3fvx46zZMSXJr166NPm5ubnaZmZnuiSeeiG6rr693wWDQvfjiiwYddoxPHgfnnFuwYIGbOXOmST9Wjhw54iS5iooK59zZ//ZJSUnu5Zdfjs75n//5HyfJbdu2zarNdvfJ4+CcczfccIO777777Jr6FDr9FdDp06e1a9cu5efnR7clJCQoPz9f27ZtM+zMxttvv63s7GyNGDFC8+fP18GDB61bMlVdXa3a2tqY8yMUCik3N7dHnh/l5eUaOHCgrr76at1zzz06evSodUvtKhwOS5LS0tIkSbt27dKZM2dizocxY8ZoyJAh3fp8+ORxOOfHP/6x0tPTNXbsWBUVFenEiRMW7bWq062G/Unvv/++mpqalJGREbM9IyND//u//2vUlY3c3FyVlJTo6quv1uHDh/XYY49pypQp2r9/v1JSUqzbM1FbWytJLZ4f5/b1FAUFBZozZ46GDx+uqqoq/f3f/71mzJihbdu2KTEx0bq9Ntfc3KwlS5Zo8uTJGjt2rKSz50Pv3r3Vr1+/mLnd+Xxo6ThI0rx58zR06FBlZ2dr3759euihh3TgwAH9x3/8h2G3sTp9AOGPZsyYEf33tddeq9zcXA0dOlT//u//rjvvvNOwM3QGt99+e/Tf48aN07XXXquRI0eqvLxcN954o2Fn7aOwsFD79+/vEZ+DXkhrx2HRokXRf48bN05ZWVm68cYbVVVVpZEjR3Z0my3q9G/BpaenKzEx8by7WOrq6pSZmWnUVefQr18/jR49WpWVldatmDl3DnB+nG/EiBFKT0/vlufH4sWLtXHjRv3iF7+I+fthmZmZOn36tOrr62Pmd9fzobXj0JLc3FxJ6lTnQ6cPoN69e2vChAnasmVLdFtzc7O2bNmiSZMmGXZm79ixY6qqqlJWVpZ1K2aGDx+uzMzMmPMjEolox44dPf78ePfdd3X06NFudX4457R48WKtXbtWr7/+uoYPHx6zf8KECUpKSoo5Hw4cOKCDBw92q/PhYsehJXv37pWkznU+WN8F8Wm89NJLLhgMupKSEvfWW2+5RYsWuX79+rna2lrr1jrU3/7t37ry8nJXXV3tfvWrX7n8/HyXnp7ujhw5Yt1au2poaHB79uxxe/bscZLcypUr3Z49e9wf/vAH55xz3/rWt1y/fv3c+vXr3b59+9zMmTPd8OHD3cmTJ407b1sXOg4NDQ1u2bJlbtu2ba66utpt3rzZXX/99e6qq65yp06dsm69zdxzzz0uFAq58vJyd/jw4eg4ceJEdM7dd9/thgwZ4l5//XW3c+dON2nSJDdp0iTDrtvexY5DZWWlW7Fihdu5c6errq5269evdyNGjHB5eXnGncfqEgHknHPf//733ZAhQ1zv3r1dTk6O2759u3VLHe62225zWVlZrnfv3u7KK690t912m6usrLRuq9394he/cJLOGwsWLHDOnb0V++GHH3YZGRkuGAy6G2+80R04cMC26XZwoeNw4sQJN23aNDdgwACXlJTkhg4d6u66665u90NaS1+/JLd69eronJMnT7qvfe1r7oorrnB9+/Z1s2fPdocPH7Zruh1c7DgcPHjQ5eXlubS0NBcMBt2oUaPcAw884MLhsG3jn8DfAwIAmOj0nwEBALonAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJj4P5SpPj0PQssIAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "class_dict = defaultdict(list)\n",
        "for f, l in traindata:\n",
        "    digits, cnt = torch.unique(l, return_counts=True)[0].numpy(), torch.unique(l, return_counts=True)[1].numpy()\n",
        "    for digit in zip(digits, cnt):\n",
        "        class_dict[digit[0]].append(digit[1])"
      ],
      "metadata": {
        "id": "nohgUSrnYR31"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_sample = {}\n",
        "for k, v in class_dict.items():\n",
        "    count_sample[k] = sum(v)\n",
        "\n",
        "count_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o87ESGO9YUBX",
        "outputId": "d0e9e783-f1e3-46e9-ff71-b5169ad1a041"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 2400,\n",
              " 1: 2400,\n",
              " 2: 2400,\n",
              " 3: 2400,\n",
              " 4: 2400,\n",
              " 5: 2400,\n",
              " 6: 2400,\n",
              " 7: 2400,\n",
              " 8: 2400,\n",
              " 9: 2400,\n",
              " 10: 2400,\n",
              " 11: 2400,\n",
              " 12: 2400,\n",
              " 13: 2400,\n",
              " 15: 2400,\n",
              " 16: 2400,\n",
              " 17: 2400,\n",
              " 18: 2400,\n",
              " 19: 2400,\n",
              " 20: 2400,\n",
              " 21: 2400,\n",
              " 22: 2400,\n",
              " 24: 2400,\n",
              " 25: 2400,\n",
              " 26: 2400,\n",
              " 27: 2400,\n",
              " 28: 2400,\n",
              " 29: 2400,\n",
              " 30: 2400,\n",
              " 31: 2400,\n",
              " 32: 2400,\n",
              " 33: 2400,\n",
              " 34: 2400,\n",
              " 35: 2400,\n",
              " 36: 2400,\n",
              " 37: 2400,\n",
              " 38: 2400,\n",
              " 39: 2400,\n",
              " 41: 2400,\n",
              " 42: 2400,\n",
              " 43: 2400,\n",
              " 44: 2400,\n",
              " 46: 2400,\n",
              " 14: 2400,\n",
              " 23: 2400,\n",
              " 40: 2400,\n",
              " 45: 2400}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(count_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c4tuafzYWGW",
        "outputId": "7a43c31f-08eb-4876-d632-6a28aed378c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ожидаемо, как и задавала в параметрах датасета - классы сбалансированы"
      ],
      "metadata": {
        "id": "_dWLPg9XYYW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "arL-TyF9Yk7J",
        "outputId": "ab0fd3cc-b897-44a0-d51f-b13b53ad2607"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy(data_iter, net):\n",
        "    acc_sum, n = 0, 0\n",
        "    net.eval()\n",
        "    for X, y in data_iter:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
        "        n += y.shape[0]\n",
        "    return acc_sum.item() / n"
      ],
      "metadata": {
        "id": "CyH1ZlXdYX-n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, train_iter, test_iter, trainer, num_epochs):\n",
        "    net.to(device)\n",
        "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
        "    net.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "\n",
        "        for i, (X, y) in enumerate(train_iter):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            trainer.zero_grad()\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y)\n",
        "            l.backward()\n",
        "            trainer.step()\n",
        "            train_l_sum += l.item()\n",
        "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
        "            n += y.shape[0]\n",
        "\n",
        "            if i % 10 == 0:\n",
        "              print(f\"Step {i}. time since epoch: {time.time() -  start:.3f}. \"\n",
        "                    f\"Train acc: {train_acc_sum / n:.3f}. Train Loss: {train_l_sum / n:.3f}\")\n",
        "        test_acc = evaluate_accuracy(test_iter, net.to(device))\n",
        "        print('-' * 20)\n",
        "        print(f'epoch {epoch + 1}, loss {train_l_sum / n:.4f}, train acc {train_acc_sum / n:.3f}'\n",
        "              f', test acc {test_acc:.3f}, time {time.time() - start:.1f} sec')"
      ],
      "metadata": {
        "id": "0b27txWBYesL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transoforms = tv.transforms.Compose([\n",
        "    tv.transforms.Grayscale(3),\n",
        "    tv.transforms.Resize((224, 224)),\n",
        "    tv.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = tv.datasets.EMNIST('.', train=True, split ='balanced', transform=transoforms, download=True)\n",
        "test_dataset = tv.datasets.EMNIST('.', train=False, split ='balanced', transform=transoforms, download=True)"
      ],
      "metadata": {
        "id": "NVgCgxNPYhtE"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 256\n",
        "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "jC1_S5n0ZTLe"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tv.models.resnet18(pretrained=True)\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yO13-HeZWo9",
        "outputId": "e5522304-3cd3-426a-ee94-196a68986c60"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_size=(3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gRQ7CajZYsd",
        "outputId": "47542e82-488e-48e7-8ca9-3f5269ce635a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                 [-1, 1000]         513,000\n",
            "================================================================\n",
            "Total params: 11,689,512\n",
            "Trainable params: 11,689,512\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 44.59\n",
            "Estimated Total Size (MB): 107.96\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Убираем требование градиента:\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "J_pISCySZa7g"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = nn.Linear(in_features=512, out_features=47)\n",
        "\n",
        "print(\"Params to learn:\")\n",
        "params_to_update = []\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJCd9heVZ5UI",
        "outputId": "c88c1122-c256-45d7-f675-4db88ad2eca8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "train(model, train_iter, test_iter, trainer, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9VMpuhsZ8K5",
        "outputId": "ec72a784-6908-4414-a871-0004fe606503"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0. time since epoch: 1.644. Train acc: 0.016. Train Loss: 4.065\n",
            "Step 10. time since epoch: 8.523. Train acc: 0.057. Train Loss: 3.726\n",
            "Step 20. time since epoch: 15.916. Train acc: 0.144. Train Loss: 3.499\n",
            "Step 30. time since epoch: 22.678. Train acc: 0.213. Train Loss: 3.295\n",
            "Step 40. time since epoch: 29.987. Train acc: 0.267. Train Loss: 3.127\n",
            "Step 50. time since epoch: 37.002. Train acc: 0.315. Train Loss: 2.977\n",
            "Step 60. time since epoch: 44.170. Train acc: 0.351. Train Loss: 2.845\n",
            "Step 70. time since epoch: 51.506. Train acc: 0.387. Train Loss: 2.725\n",
            "Step 80. time since epoch: 58.315. Train acc: 0.412. Train Loss: 2.620\n",
            "Step 90. time since epoch: 65.731. Train acc: 0.435. Train Loss: 2.522\n",
            "Step 100. time since epoch: 72.732. Train acc: 0.456. Train Loss: 2.437\n",
            "Step 110. time since epoch: 80.158. Train acc: 0.473. Train Loss: 2.360\n",
            "Step 120. time since epoch: 87.168. Train acc: 0.488. Train Loss: 2.292\n",
            "Step 130. time since epoch: 94.392. Train acc: 0.500. Train Loss: 2.230\n",
            "Step 140. time since epoch: 102.454. Train acc: 0.512. Train Loss: 2.171\n",
            "Step 150. time since epoch: 109.236. Train acc: 0.523. Train Loss: 2.117\n",
            "Step 160. time since epoch: 116.675. Train acc: 0.534. Train Loss: 2.067\n",
            "Step 170. time since epoch: 123.543. Train acc: 0.544. Train Loss: 2.020\n",
            "Step 180. time since epoch: 131.015. Train acc: 0.553. Train Loss: 1.978\n",
            "Step 190. time since epoch: 138.076. Train acc: 0.561. Train Loss: 1.938\n",
            "Step 200. time since epoch: 145.170. Train acc: 0.568. Train Loss: 1.900\n",
            "Step 210. time since epoch: 152.537. Train acc: 0.574. Train Loss: 1.866\n",
            "Step 220. time since epoch: 159.412. Train acc: 0.581. Train Loss: 1.835\n",
            "Step 230. time since epoch: 166.857. Train acc: 0.587. Train Loss: 1.804\n",
            "Step 240. time since epoch: 173.636. Train acc: 0.592. Train Loss: 1.776\n",
            "Step 250. time since epoch: 181.053. Train acc: 0.597. Train Loss: 1.750\n",
            "Step 260. time since epoch: 188.081. Train acc: 0.602. Train Loss: 1.724\n",
            "Step 270. time since epoch: 195.321. Train acc: 0.606. Train Loss: 1.700\n",
            "Step 280. time since epoch: 202.782. Train acc: 0.611. Train Loss: 1.675\n",
            "Step 290. time since epoch: 209.649. Train acc: 0.616. Train Loss: 1.652\n",
            "Step 300. time since epoch: 217.232. Train acc: 0.620. Train Loss: 1.631\n",
            "Step 310. time since epoch: 224.146. Train acc: 0.624. Train Loss: 1.610\n",
            "Step 320. time since epoch: 231.422. Train acc: 0.627. Train Loss: 1.590\n",
            "Step 330. time since epoch: 238.342. Train acc: 0.631. Train Loss: 1.572\n",
            "Step 340. time since epoch: 245.777. Train acc: 0.634. Train Loss: 1.554\n",
            "Step 350. time since epoch: 253.065. Train acc: 0.637. Train Loss: 1.537\n",
            "Step 360. time since epoch: 259.956. Train acc: 0.640. Train Loss: 1.521\n",
            "Step 370. time since epoch: 267.380. Train acc: 0.643. Train Loss: 1.506\n",
            "Step 380. time since epoch: 274.175. Train acc: 0.646. Train Loss: 1.491\n",
            "Step 390. time since epoch: 281.686. Train acc: 0.648. Train Loss: 1.477\n",
            "Step 400. time since epoch: 288.538. Train acc: 0.650. Train Loss: 1.463\n",
            "Step 410. time since epoch: 295.956. Train acc: 0.653. Train Loss: 1.450\n",
            "Step 420. time since epoch: 303.407. Train acc: 0.655. Train Loss: 1.437\n",
            "Step 430. time since epoch: 310.298. Train acc: 0.657. Train Loss: 1.425\n",
            "Step 440. time since epoch: 317.489. Train acc: 0.659. Train Loss: 1.414\n",
            "--------------------\n",
            "epoch 1, loss 1.4135, train acc 0.659, test acc 0.758, time 352.8 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pv_table = {}\n",
        "pv_table['resnet18'] = {'epoch': 1, 'loss': 1.4135, 'train_acc': 0.659, 'test_acc': 0.758}\n",
        "pv_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2QekflgaAxl",
        "outputId": "03371b78-396f-4eb1-db2f-a6d2d92081af"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'resnet18': {'epoch': 1,\n",
              "  'loss': 1.4135,\n",
              "  'train_acc': 0.659,\n",
              "  'test_acc': 0.758}}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tv.models.vgg16(pretrained=True)\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd5D-8RubefQ",
        "outputId": "7ee40092-89b9-4b8d-f1be-38f63561a559"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_size=(3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49BjpXXdbyH2",
        "outputId": "4bfe0398-d207-4335-89f0-409418adc3ea"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "              ReLU-2         [-1, 64, 224, 224]               0\n",
            "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
            "              ReLU-4         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
            "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
            "              ReLU-7        [-1, 128, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
            "              ReLU-9        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
            "             ReLU-12          [-1, 256, 56, 56]               0\n",
            "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-14          [-1, 256, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-16          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
            "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
            "             ReLU-19          [-1, 512, 28, 28]               0\n",
            "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-21          [-1, 512, 28, 28]               0\n",
            "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-23          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
            "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-26          [-1, 512, 14, 14]               0\n",
            "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-28          [-1, 512, 14, 14]               0\n",
            "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-30          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
            "           Linear-33                 [-1, 4096]     102,764,544\n",
            "             ReLU-34                 [-1, 4096]               0\n",
            "          Dropout-35                 [-1, 4096]               0\n",
            "           Linear-36                 [-1, 4096]      16,781,312\n",
            "             ReLU-37                 [-1, 4096]               0\n",
            "          Dropout-38                 [-1, 4096]               0\n",
            "           Linear-39                 [-1, 1000]       4,097,000\n",
            "================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 218.78\n",
            "Params size (MB): 527.79\n",
            "Estimated Total Size (MB): 747.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Убираем требование градиента:\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "0qJRrRMvb0Il"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier[6] = nn.Linear(in_features=4096, out_features=47)\n",
        "\n",
        "print(\"Params to learn:\")\n",
        "params_to_update = []\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqDKh8WacPyP",
        "outputId": "38d62959-3bcc-434b-c09b-d5b3f0b04824"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "\t classifier.6.weight\n",
            "\t classifier.6.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "train(model, train_iter, test_iter, trainer, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEKt0VwLcVNG",
        "outputId": "c1b32c83-83a8-4ec6-ada1-674ed9032955"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0. time since epoch: 2.134. Train acc: 0.031. Train Loss: 3.903\n",
            "Step 10. time since epoch: 19.687. Train acc: 0.110. Train Loss: 3.535\n",
            "Step 20. time since epoch: 37.374. Train acc: 0.200. Train Loss: 3.230\n",
            "Step 30. time since epoch: 55.217. Train acc: 0.258. Train Loss: 2.991\n",
            "Step 40. time since epoch: 72.405. Train acc: 0.296. Train Loss: 2.825\n",
            "Step 50. time since epoch: 90.473. Train acc: 0.325. Train Loss: 2.687\n",
            "Step 60. time since epoch: 108.156. Train acc: 0.347. Train Loss: 2.581\n",
            "Step 70. time since epoch: 125.827. Train acc: 0.367. Train Loss: 2.488\n",
            "Step 80. time since epoch: 142.955. Train acc: 0.384. Train Loss: 2.406\n",
            "Step 90. time since epoch: 160.526. Train acc: 0.399. Train Loss: 2.334\n",
            "Step 100. time since epoch: 178.667. Train acc: 0.413. Train Loss: 2.272\n",
            "Step 110. time since epoch: 196.117. Train acc: 0.425. Train Loss: 2.217\n",
            "Step 120. time since epoch: 213.603. Train acc: 0.434. Train Loss: 2.171\n",
            "Step 130. time since epoch: 231.033. Train acc: 0.441. Train Loss: 2.131\n",
            "Step 140. time since epoch: 248.175. Train acc: 0.449. Train Loss: 2.091\n",
            "Step 150. time since epoch: 265.838. Train acc: 0.457. Train Loss: 2.054\n",
            "Step 160. time since epoch: 283.114. Train acc: 0.465. Train Loss: 2.021\n",
            "Step 170. time since epoch: 300.400. Train acc: 0.471. Train Loss: 1.991\n",
            "Step 180. time since epoch: 318.077. Train acc: 0.478. Train Loss: 1.962\n",
            "Step 190. time since epoch: 335.270. Train acc: 0.484. Train Loss: 1.936\n",
            "Step 200. time since epoch: 352.762. Train acc: 0.488. Train Loss: 1.913\n",
            "Step 210. time since epoch: 370.277. Train acc: 0.493. Train Loss: 1.891\n",
            "Step 220. time since epoch: 387.541. Train acc: 0.497. Train Loss: 1.871\n",
            "Step 230. time since epoch: 405.248. Train acc: 0.501. Train Loss: 1.850\n",
            "Step 240. time since epoch: 422.468. Train acc: 0.504. Train Loss: 1.833\n",
            "Step 250. time since epoch: 439.860. Train acc: 0.507. Train Loss: 1.816\n",
            "Step 260. time since epoch: 457.757. Train acc: 0.511. Train Loss: 1.800\n",
            "Step 270. time since epoch: 474.940. Train acc: 0.515. Train Loss: 1.785\n",
            "Step 280. time since epoch: 492.330. Train acc: 0.518. Train Loss: 1.770\n",
            "Step 290. time since epoch: 509.836. Train acc: 0.521. Train Loss: 1.755\n",
            "Step 300. time since epoch: 527.068. Train acc: 0.524. Train Loss: 1.743\n",
            "Step 310. time since epoch: 544.714. Train acc: 0.527. Train Loss: 1.729\n",
            "Step 320. time since epoch: 561.964. Train acc: 0.529. Train Loss: 1.716\n",
            "Step 330. time since epoch: 579.173. Train acc: 0.532. Train Loss: 1.705\n",
            "Step 340. time since epoch: 596.881. Train acc: 0.534. Train Loss: 1.695\n",
            "Step 350. time since epoch: 614.057. Train acc: 0.536. Train Loss: 1.685\n",
            "Step 360. time since epoch: 631.469. Train acc: 0.538. Train Loss: 1.674\n",
            "Step 370. time since epoch: 648.977. Train acc: 0.540. Train Loss: 1.665\n",
            "Step 380. time since epoch: 666.205. Train acc: 0.542. Train Loss: 1.655\n",
            "Step 390. time since epoch: 683.896. Train acc: 0.544. Train Loss: 1.647\n",
            "Step 400. time since epoch: 701.106. Train acc: 0.545. Train Loss: 1.638\n",
            "Step 410. time since epoch: 718.326. Train acc: 0.546. Train Loss: 1.631\n",
            "Step 420. time since epoch: 736.014. Train acc: 0.548. Train Loss: 1.621\n",
            "Step 430. time since epoch: 753.408. Train acc: 0.550. Train Loss: 1.613\n",
            "Step 440. time since epoch: 770.347. Train acc: 0.552. Train Loss: 1.605\n",
            "--------------------\n",
            "epoch 1, loss 1.6052, train acc 0.552, test acc 0.711, time 867.2 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pv_table['vgg16'] = {'epoch': 1, 'loss': 1.6052, 'train_acc': 0.552, 'test_acc': 0.711}\n",
        "pv_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCSoQ-iGcrph",
        "outputId": "c748afb7-8115-4454-f10a-4749145a7bff"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'resnet18': {'epoch': 1,\n",
              "  'loss': 1.4135,\n",
              "  'train_acc': 0.659,\n",
              "  'test_acc': 0.758},\n",
              " 'vgg16': {'epoch': 1, 'loss': 1.6052, 'train_acc': 0.552, 'test_acc': 0.711}}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tv.models.inception_v3(pretrained=True)\n",
        "model.cuda()\n",
        "model.aux_logits = False"
      ],
      "metadata": {
        "id": "cXXrln-scZ8f"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_size=(3, 299, 299))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLuGiK-Vp1bG",
        "outputId": "b90f46e2-e4db-4e87-82ce-f23340379097"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 149, 149]             864\n",
            "       BatchNorm2d-2         [-1, 32, 149, 149]              64\n",
            "       BasicConv2d-3         [-1, 32, 149, 149]               0\n",
            "            Conv2d-4         [-1, 32, 147, 147]           9,216\n",
            "       BatchNorm2d-5         [-1, 32, 147, 147]              64\n",
            "       BasicConv2d-6         [-1, 32, 147, 147]               0\n",
            "            Conv2d-7         [-1, 64, 147, 147]          18,432\n",
            "       BatchNorm2d-8         [-1, 64, 147, 147]             128\n",
            "       BasicConv2d-9         [-1, 64, 147, 147]               0\n",
            "        MaxPool2d-10           [-1, 64, 73, 73]               0\n",
            "           Conv2d-11           [-1, 80, 73, 73]           5,120\n",
            "      BatchNorm2d-12           [-1, 80, 73, 73]             160\n",
            "      BasicConv2d-13           [-1, 80, 73, 73]               0\n",
            "           Conv2d-14          [-1, 192, 71, 71]         138,240\n",
            "      BatchNorm2d-15          [-1, 192, 71, 71]             384\n",
            "      BasicConv2d-16          [-1, 192, 71, 71]               0\n",
            "        MaxPool2d-17          [-1, 192, 35, 35]               0\n",
            "           Conv2d-18           [-1, 64, 35, 35]          12,288\n",
            "      BatchNorm2d-19           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-20           [-1, 64, 35, 35]               0\n",
            "           Conv2d-21           [-1, 48, 35, 35]           9,216\n",
            "      BatchNorm2d-22           [-1, 48, 35, 35]              96\n",
            "      BasicConv2d-23           [-1, 48, 35, 35]               0\n",
            "           Conv2d-24           [-1, 64, 35, 35]          76,800\n",
            "      BatchNorm2d-25           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-26           [-1, 64, 35, 35]               0\n",
            "           Conv2d-27           [-1, 64, 35, 35]          12,288\n",
            "      BatchNorm2d-28           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-29           [-1, 64, 35, 35]               0\n",
            "           Conv2d-30           [-1, 96, 35, 35]          55,296\n",
            "      BatchNorm2d-31           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-32           [-1, 96, 35, 35]               0\n",
            "           Conv2d-33           [-1, 96, 35, 35]          82,944\n",
            "      BatchNorm2d-34           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-35           [-1, 96, 35, 35]               0\n",
            "           Conv2d-36           [-1, 32, 35, 35]           6,144\n",
            "      BatchNorm2d-37           [-1, 32, 35, 35]              64\n",
            "      BasicConv2d-38           [-1, 32, 35, 35]               0\n",
            "       InceptionA-39          [-1, 256, 35, 35]               0\n",
            "           Conv2d-40           [-1, 64, 35, 35]          16,384\n",
            "      BatchNorm2d-41           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-42           [-1, 64, 35, 35]               0\n",
            "           Conv2d-43           [-1, 48, 35, 35]          12,288\n",
            "      BatchNorm2d-44           [-1, 48, 35, 35]              96\n",
            "      BasicConv2d-45           [-1, 48, 35, 35]               0\n",
            "           Conv2d-46           [-1, 64, 35, 35]          76,800\n",
            "      BatchNorm2d-47           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-48           [-1, 64, 35, 35]               0\n",
            "           Conv2d-49           [-1, 64, 35, 35]          16,384\n",
            "      BatchNorm2d-50           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-51           [-1, 64, 35, 35]               0\n",
            "           Conv2d-52           [-1, 96, 35, 35]          55,296\n",
            "      BatchNorm2d-53           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-54           [-1, 96, 35, 35]               0\n",
            "           Conv2d-55           [-1, 96, 35, 35]          82,944\n",
            "      BatchNorm2d-56           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-57           [-1, 96, 35, 35]               0\n",
            "           Conv2d-58           [-1, 64, 35, 35]          16,384\n",
            "      BatchNorm2d-59           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-60           [-1, 64, 35, 35]               0\n",
            "       InceptionA-61          [-1, 288, 35, 35]               0\n",
            "           Conv2d-62           [-1, 64, 35, 35]          18,432\n",
            "      BatchNorm2d-63           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-64           [-1, 64, 35, 35]               0\n",
            "           Conv2d-65           [-1, 48, 35, 35]          13,824\n",
            "      BatchNorm2d-66           [-1, 48, 35, 35]              96\n",
            "      BasicConv2d-67           [-1, 48, 35, 35]               0\n",
            "           Conv2d-68           [-1, 64, 35, 35]          76,800\n",
            "      BatchNorm2d-69           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-70           [-1, 64, 35, 35]               0\n",
            "           Conv2d-71           [-1, 64, 35, 35]          18,432\n",
            "      BatchNorm2d-72           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-73           [-1, 64, 35, 35]               0\n",
            "           Conv2d-74           [-1, 96, 35, 35]          55,296\n",
            "      BatchNorm2d-75           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-76           [-1, 96, 35, 35]               0\n",
            "           Conv2d-77           [-1, 96, 35, 35]          82,944\n",
            "      BatchNorm2d-78           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-79           [-1, 96, 35, 35]               0\n",
            "           Conv2d-80           [-1, 64, 35, 35]          18,432\n",
            "      BatchNorm2d-81           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-82           [-1, 64, 35, 35]               0\n",
            "       InceptionA-83          [-1, 288, 35, 35]               0\n",
            "           Conv2d-84          [-1, 384, 17, 17]         995,328\n",
            "      BatchNorm2d-85          [-1, 384, 17, 17]             768\n",
            "      BasicConv2d-86          [-1, 384, 17, 17]               0\n",
            "           Conv2d-87           [-1, 64, 35, 35]          18,432\n",
            "      BatchNorm2d-88           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-89           [-1, 64, 35, 35]               0\n",
            "           Conv2d-90           [-1, 96, 35, 35]          55,296\n",
            "      BatchNorm2d-91           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-92           [-1, 96, 35, 35]               0\n",
            "           Conv2d-93           [-1, 96, 17, 17]          82,944\n",
            "      BatchNorm2d-94           [-1, 96, 17, 17]             192\n",
            "      BasicConv2d-95           [-1, 96, 17, 17]               0\n",
            "       InceptionB-96          [-1, 768, 17, 17]               0\n",
            "           Conv2d-97          [-1, 192, 17, 17]         147,456\n",
            "      BatchNorm2d-98          [-1, 192, 17, 17]             384\n",
            "      BasicConv2d-99          [-1, 192, 17, 17]               0\n",
            "          Conv2d-100          [-1, 128, 17, 17]          98,304\n",
            "     BatchNorm2d-101          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-102          [-1, 128, 17, 17]               0\n",
            "          Conv2d-103          [-1, 128, 17, 17]         114,688\n",
            "     BatchNorm2d-104          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-105          [-1, 128, 17, 17]               0\n",
            "          Conv2d-106          [-1, 192, 17, 17]         172,032\n",
            "     BatchNorm2d-107          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-108          [-1, 192, 17, 17]               0\n",
            "          Conv2d-109          [-1, 128, 17, 17]          98,304\n",
            "     BatchNorm2d-110          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-111          [-1, 128, 17, 17]               0\n",
            "          Conv2d-112          [-1, 128, 17, 17]         114,688\n",
            "     BatchNorm2d-113          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-114          [-1, 128, 17, 17]               0\n",
            "          Conv2d-115          [-1, 128, 17, 17]         114,688\n",
            "     BatchNorm2d-116          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-117          [-1, 128, 17, 17]               0\n",
            "          Conv2d-118          [-1, 128, 17, 17]         114,688\n",
            "     BatchNorm2d-119          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-120          [-1, 128, 17, 17]               0\n",
            "          Conv2d-121          [-1, 192, 17, 17]         172,032\n",
            "     BatchNorm2d-122          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-123          [-1, 192, 17, 17]               0\n",
            "          Conv2d-124          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-125          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-126          [-1, 192, 17, 17]               0\n",
            "      InceptionC-127          [-1, 768, 17, 17]               0\n",
            "          Conv2d-128          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-129          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-130          [-1, 192, 17, 17]               0\n",
            "          Conv2d-131          [-1, 160, 17, 17]         122,880\n",
            "     BatchNorm2d-132          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-133          [-1, 160, 17, 17]               0\n",
            "          Conv2d-134          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-135          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-136          [-1, 160, 17, 17]               0\n",
            "          Conv2d-137          [-1, 192, 17, 17]         215,040\n",
            "     BatchNorm2d-138          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-139          [-1, 192, 17, 17]               0\n",
            "          Conv2d-140          [-1, 160, 17, 17]         122,880\n",
            "     BatchNorm2d-141          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-142          [-1, 160, 17, 17]               0\n",
            "          Conv2d-143          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-144          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-145          [-1, 160, 17, 17]               0\n",
            "          Conv2d-146          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-147          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-148          [-1, 160, 17, 17]               0\n",
            "          Conv2d-149          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-150          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-151          [-1, 160, 17, 17]               0\n",
            "          Conv2d-152          [-1, 192, 17, 17]         215,040\n",
            "     BatchNorm2d-153          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-154          [-1, 192, 17, 17]               0\n",
            "          Conv2d-155          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-156          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-157          [-1, 192, 17, 17]               0\n",
            "      InceptionC-158          [-1, 768, 17, 17]               0\n",
            "          Conv2d-159          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-160          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-161          [-1, 192, 17, 17]               0\n",
            "          Conv2d-162          [-1, 160, 17, 17]         122,880\n",
            "     BatchNorm2d-163          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-164          [-1, 160, 17, 17]               0\n",
            "          Conv2d-165          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-166          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-167          [-1, 160, 17, 17]               0\n",
            "          Conv2d-168          [-1, 192, 17, 17]         215,040\n",
            "     BatchNorm2d-169          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-170          [-1, 192, 17, 17]               0\n",
            "          Conv2d-171          [-1, 160, 17, 17]         122,880\n",
            "     BatchNorm2d-172          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-173          [-1, 160, 17, 17]               0\n",
            "          Conv2d-174          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-175          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-176          [-1, 160, 17, 17]               0\n",
            "          Conv2d-177          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-178          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-179          [-1, 160, 17, 17]               0\n",
            "          Conv2d-180          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-181          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-182          [-1, 160, 17, 17]               0\n",
            "          Conv2d-183          [-1, 192, 17, 17]         215,040\n",
            "     BatchNorm2d-184          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-185          [-1, 192, 17, 17]               0\n",
            "          Conv2d-186          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-187          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-188          [-1, 192, 17, 17]               0\n",
            "      InceptionC-189          [-1, 768, 17, 17]               0\n",
            "          Conv2d-190          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-191          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-192          [-1, 192, 17, 17]               0\n",
            "          Conv2d-193          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-194          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-195          [-1, 192, 17, 17]               0\n",
            "          Conv2d-196          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-197          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-198          [-1, 192, 17, 17]               0\n",
            "          Conv2d-199          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-200          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-201          [-1, 192, 17, 17]               0\n",
            "          Conv2d-202          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-203          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-204          [-1, 192, 17, 17]               0\n",
            "          Conv2d-205          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-206          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-207          [-1, 192, 17, 17]               0\n",
            "          Conv2d-208          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-209          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-210          [-1, 192, 17, 17]               0\n",
            "          Conv2d-211          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-212          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-213          [-1, 192, 17, 17]               0\n",
            "          Conv2d-214          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-215          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-216          [-1, 192, 17, 17]               0\n",
            "          Conv2d-217          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-218          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-219          [-1, 192, 17, 17]               0\n",
            "      InceptionC-220          [-1, 768, 17, 17]               0\n",
            "          Conv2d-221            [-1, 128, 5, 5]          98,304\n",
            "     BatchNorm2d-222            [-1, 128, 5, 5]             256\n",
            "     BasicConv2d-223            [-1, 128, 5, 5]               0\n",
            "          Conv2d-224            [-1, 768, 1, 1]       2,457,600\n",
            "     BatchNorm2d-225            [-1, 768, 1, 1]           1,536\n",
            "     BasicConv2d-226            [-1, 768, 1, 1]               0\n",
            "          Linear-227                 [-1, 1000]         769,000\n",
            "    InceptionAux-228                 [-1, 1000]               0\n",
            "          Conv2d-229          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-230          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-231          [-1, 192, 17, 17]               0\n",
            "          Conv2d-232            [-1, 320, 8, 8]         552,960\n",
            "     BatchNorm2d-233            [-1, 320, 8, 8]             640\n",
            "     BasicConv2d-234            [-1, 320, 8, 8]               0\n",
            "          Conv2d-235          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-236          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-237          [-1, 192, 17, 17]               0\n",
            "          Conv2d-238          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-239          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-240          [-1, 192, 17, 17]               0\n",
            "          Conv2d-241          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-242          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-243          [-1, 192, 17, 17]               0\n",
            "          Conv2d-244            [-1, 192, 8, 8]         331,776\n",
            "     BatchNorm2d-245            [-1, 192, 8, 8]             384\n",
            "     BasicConv2d-246            [-1, 192, 8, 8]               0\n",
            "      InceptionD-247           [-1, 1280, 8, 8]               0\n",
            "          Conv2d-248            [-1, 320, 8, 8]         409,600\n",
            "     BatchNorm2d-249            [-1, 320, 8, 8]             640\n",
            "     BasicConv2d-250            [-1, 320, 8, 8]               0\n",
            "          Conv2d-251            [-1, 384, 8, 8]         491,520\n",
            "     BatchNorm2d-252            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-253            [-1, 384, 8, 8]               0\n",
            "          Conv2d-254            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-255            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-256            [-1, 384, 8, 8]               0\n",
            "          Conv2d-257            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-258            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-259            [-1, 384, 8, 8]               0\n",
            "          Conv2d-260            [-1, 448, 8, 8]         573,440\n",
            "     BatchNorm2d-261            [-1, 448, 8, 8]             896\n",
            "     BasicConv2d-262            [-1, 448, 8, 8]               0\n",
            "          Conv2d-263            [-1, 384, 8, 8]       1,548,288\n",
            "     BatchNorm2d-264            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-265            [-1, 384, 8, 8]               0\n",
            "          Conv2d-266            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-267            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-268            [-1, 384, 8, 8]               0\n",
            "          Conv2d-269            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-270            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-271            [-1, 384, 8, 8]               0\n",
            "          Conv2d-272            [-1, 192, 8, 8]         245,760\n",
            "     BatchNorm2d-273            [-1, 192, 8, 8]             384\n",
            "     BasicConv2d-274            [-1, 192, 8, 8]               0\n",
            "      InceptionE-275           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-276            [-1, 320, 8, 8]         655,360\n",
            "     BatchNorm2d-277            [-1, 320, 8, 8]             640\n",
            "     BasicConv2d-278            [-1, 320, 8, 8]               0\n",
            "          Conv2d-279            [-1, 384, 8, 8]         786,432\n",
            "     BatchNorm2d-280            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-281            [-1, 384, 8, 8]               0\n",
            "          Conv2d-282            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-283            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-284            [-1, 384, 8, 8]               0\n",
            "          Conv2d-285            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-286            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-287            [-1, 384, 8, 8]               0\n",
            "          Conv2d-288            [-1, 448, 8, 8]         917,504\n",
            "     BatchNorm2d-289            [-1, 448, 8, 8]             896\n",
            "     BasicConv2d-290            [-1, 448, 8, 8]               0\n",
            "          Conv2d-291            [-1, 384, 8, 8]       1,548,288\n",
            "     BatchNorm2d-292            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-293            [-1, 384, 8, 8]               0\n",
            "          Conv2d-294            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-295            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-296            [-1, 384, 8, 8]               0\n",
            "          Conv2d-297            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-298            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-299            [-1, 384, 8, 8]               0\n",
            "          Conv2d-300            [-1, 192, 8, 8]         393,216\n",
            "     BatchNorm2d-301            [-1, 192, 8, 8]             384\n",
            "     BasicConv2d-302            [-1, 192, 8, 8]               0\n",
            "      InceptionE-303           [-1, 2048, 8, 8]               0\n",
            "AdaptiveAvgPool2d-304           [-1, 2048, 1, 1]               0\n",
            "         Dropout-305           [-1, 2048, 1, 1]               0\n",
            "          Linear-306                 [-1, 1000]       2,049,000\n",
            "================================================================\n",
            "Total params: 27,161,264\n",
            "Trainable params: 27,161,264\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.02\n",
            "Forward/backward pass size (MB): 228.66\n",
            "Params size (MB): 103.61\n",
            "Estimated Total Size (MB): 333.29\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BATCH_SIZE = 256\n",
        "transforms = tv.transforms.Compose([\n",
        "    tv.transforms.Grayscale(3),\n",
        "    tv.transforms.Resize((299, 299)),\n",
        "    tv.transforms.ToTensor(),\n",
        "    tv.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "cU3edPGdc_88"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tv.datasets.EMNIST('.', train=True, split ='balanced', transform=transforms, download=True)\n",
        "test_dataset = tv.datasets.EMNIST('.', train=False, split ='balanced', transform=transforms, download=True)\n",
        "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "a-nPtEPfnInD"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Убираем требование градиента:\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "GUTlw3r6qlyr"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = nn.Linear(in_features=2048, out_features=47)\n",
        "\n",
        "print(\"Params to learn:\")\n",
        "params_to_update = []\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBiikuFWqlwP",
        "outputId": "eccc73da-870e-45a9-8f98-abfd9528de1f"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "train(model, train_iter, test_iter, trainer, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY5COtYXq5fK",
        "outputId": "da870dee-c2f2-4d07-b22f-b8130d8b1eb9"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0. time since epoch: 1.982. Train acc: 0.008. Train Loss: 3.881\n",
            "Step 10. time since epoch: 22.620. Train acc: 0.055. Train Loss: 3.764\n",
            "Step 20. time since epoch: 42.920. Train acc: 0.114. Train Loss: 3.624\n",
            "Step 30. time since epoch: 63.997. Train acc: 0.162. Train Loss: 3.489\n",
            "Step 40. time since epoch: 84.109. Train acc: 0.198. Train Loss: 3.374\n",
            "Step 50. time since epoch: 104.209. Train acc: 0.229. Train Loss: 3.267\n",
            "Step 60. time since epoch: 124.467. Train acc: 0.252. Train Loss: 3.176\n",
            "Step 70. time since epoch: 144.611. Train acc: 0.274. Train Loss: 3.092\n",
            "Step 80. time since epoch: 164.566. Train acc: 0.293. Train Loss: 3.016\n",
            "Step 90. time since epoch: 184.717. Train acc: 0.310. Train Loss: 2.942\n",
            "Step 100. time since epoch: 204.554. Train acc: 0.325. Train Loss: 2.878\n",
            "Step 110. time since epoch: 224.613. Train acc: 0.336. Train Loss: 2.820\n",
            "Step 120. time since epoch: 244.454. Train acc: 0.347. Train Loss: 2.766\n",
            "Step 130. time since epoch: 264.732. Train acc: 0.356. Train Loss: 2.716\n",
            "Step 140. time since epoch: 284.991. Train acc: 0.366. Train Loss: 2.667\n",
            "Step 150. time since epoch: 304.855. Train acc: 0.374. Train Loss: 2.623\n",
            "Step 160. time since epoch: 325.015. Train acc: 0.383. Train Loss: 2.581\n",
            "Step 170. time since epoch: 345.024. Train acc: 0.391. Train Loss: 2.543\n",
            "Step 180. time since epoch: 365.495. Train acc: 0.399. Train Loss: 2.508\n",
            "Step 190. time since epoch: 385.925. Train acc: 0.405. Train Loss: 2.475\n",
            "Step 200. time since epoch: 406.451. Train acc: 0.410. Train Loss: 2.443\n",
            "Step 210. time since epoch: 426.858. Train acc: 0.416. Train Loss: 2.414\n",
            "Step 220. time since epoch: 446.693. Train acc: 0.420. Train Loss: 2.389\n",
            "Step 230. time since epoch: 467.054. Train acc: 0.425. Train Loss: 2.362\n",
            "Step 240. time since epoch: 487.188. Train acc: 0.429. Train Loss: 2.338\n",
            "Step 250. time since epoch: 507.581. Train acc: 0.433. Train Loss: 2.315\n",
            "Step 260. time since epoch: 527.711. Train acc: 0.437. Train Loss: 2.293\n",
            "Step 270. time since epoch: 547.720. Train acc: 0.441. Train Loss: 2.272\n",
            "Step 280. time since epoch: 567.979. Train acc: 0.444. Train Loss: 2.251\n",
            "Step 290. time since epoch: 587.930. Train acc: 0.448. Train Loss: 2.230\n",
            "Step 300. time since epoch: 608.313. Train acc: 0.451. Train Loss: 2.211\n",
            "Step 310. time since epoch: 628.396. Train acc: 0.454. Train Loss: 2.193\n",
            "Step 320. time since epoch: 648.793. Train acc: 0.457. Train Loss: 2.175\n",
            "Step 330. time since epoch: 669.291. Train acc: 0.460. Train Loss: 2.158\n",
            "Step 340. time since epoch: 689.164. Train acc: 0.462. Train Loss: 2.143\n",
            "Step 350. time since epoch: 709.451. Train acc: 0.465. Train Loss: 2.129\n",
            "Step 360. time since epoch: 729.402. Train acc: 0.467. Train Loss: 2.114\n",
            "Step 370. time since epoch: 749.739. Train acc: 0.469. Train Loss: 2.101\n",
            "Step 380. time since epoch: 770.243. Train acc: 0.471. Train Loss: 2.088\n",
            "Step 390. time since epoch: 790.960. Train acc: 0.474. Train Loss: 2.075\n",
            "Step 400. time since epoch: 811.651. Train acc: 0.476. Train Loss: 2.062\n",
            "Step 410. time since epoch: 831.876. Train acc: 0.478. Train Loss: 2.051\n",
            "Step 420. time since epoch: 852.269. Train acc: 0.480. Train Loss: 2.038\n",
            "Step 430. time since epoch: 872.181. Train acc: 0.482. Train Loss: 2.027\n",
            "Step 440. time since epoch: 891.775. Train acc: 0.484. Train Loss: 2.017\n",
            "--------------------\n",
            "epoch 1, loss 2.0168, train acc 0.484, test acc 0.636, time 971.2 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pv_table['inception_v3'] = {'epoch': 1, 'loss': 2.0168, 'train_acc': 0.484, 'test_acc': 0.636}\n",
        "pv_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Qr5rHN1dEam",
        "outputId": "d21a202e-967c-46c2-bd01-f1761bc8f1fe"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'resnet18': {'epoch': 1,\n",
              "  'loss': 1.4135,\n",
              "  'train_acc': 0.659,\n",
              "  'test_acc': 0.758},\n",
              " 'vgg16': {'epoch': 1, 'loss': 1.6052, 'train_acc': 0.552, 'test_acc': 0.711},\n",
              " 'inception_v3': {'epoch': 1,\n",
              "  'loss': 2.0168,\n",
              "  'train_acc': 0.484,\n",
              "  'test_acc': 0.636}}"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tv.models.densenet161(weights=True)"
      ],
      "metadata": {
        "id": "pDRR_edFxFr9"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BV-8TITxrk3",
        "outputId": "24cf37c3-15b4-407d-a057-af1eca218c2a"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=2208, out_features=1000, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Убираем требование градиента:\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "v6wX6fe6x0VT"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier = nn.Linear(in_features=2208, out_features=47)"
      ],
      "metadata": {
        "id": "ppTTWhlbx3wN"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Params to learn:\")\n",
        "params_to_update = []\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MABg1oR-x6QT",
        "outputId": "13515177-f048-46b2-a995-22874e1b1ceb"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "\t classifier.weight\n",
            "\t classifier.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = torch.optim.Adam(params_to_update, lr=0.001)"
      ],
      "metadata": {
        "id": "5EQJTo21x8_o"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, train_iter, test_iter, trainer, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPtyYPtsx_9H",
        "outputId": "de809bb1-1219-4149-d202-5f1ca46cbad2"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0. time since epoch: 2.447. Train acc: 0.012. Train Loss: 3.905\n",
            "Step 10. time since epoch: 25.232. Train acc: 0.119. Train Loss: 3.627\n",
            "Step 20. time since epoch: 48.818. Train acc: 0.209. Train Loss: 3.368\n",
            "Step 30. time since epoch: 72.832. Train acc: 0.278. Train Loss: 3.143\n",
            "Step 40. time since epoch: 96.422. Train acc: 0.327. Train Loss: 2.963\n",
            "Step 50. time since epoch: 119.898. Train acc: 0.370. Train Loss: 2.805\n",
            "Step 60. time since epoch: 143.643. Train acc: 0.398. Train Loss: 2.678\n",
            "Step 70. time since epoch: 167.328. Train acc: 0.424. Train Loss: 2.564\n",
            "Step 80. time since epoch: 190.751. Train acc: 0.445. Train Loss: 2.464\n",
            "Step 90. time since epoch: 214.326. Train acc: 0.465. Train Loss: 2.374\n",
            "Step 100. time since epoch: 238.094. Train acc: 0.481. Train Loss: 2.294\n",
            "Step 110. time since epoch: 261.766. Train acc: 0.496. Train Loss: 2.222\n",
            "Step 120. time since epoch: 285.442. Train acc: 0.509. Train Loss: 2.158\n",
            "Step 130. time since epoch: 309.119. Train acc: 0.521. Train Loss: 2.102\n",
            "Step 140. time since epoch: 332.814. Train acc: 0.532. Train Loss: 2.048\n",
            "Step 150. time since epoch: 356.458. Train acc: 0.543. Train Loss: 1.997\n",
            "Step 160. time since epoch: 380.194. Train acc: 0.552. Train Loss: 1.951\n",
            "Step 170. time since epoch: 403.888. Train acc: 0.561. Train Loss: 1.910\n",
            "Step 180. time since epoch: 427.608. Train acc: 0.568. Train Loss: 1.871\n",
            "Step 190. time since epoch: 451.270. Train acc: 0.575. Train Loss: 1.835\n",
            "Step 200. time since epoch: 475.049. Train acc: 0.582. Train Loss: 1.801\n",
            "Step 210. time since epoch: 498.746. Train acc: 0.588. Train Loss: 1.770\n",
            "Step 220. time since epoch: 522.603. Train acc: 0.593. Train Loss: 1.742\n",
            "Step 230. time since epoch: 546.397. Train acc: 0.599. Train Loss: 1.714\n",
            "Step 240. time since epoch: 570.263. Train acc: 0.604. Train Loss: 1.689\n",
            "Step 250. time since epoch: 594.007. Train acc: 0.608. Train Loss: 1.665\n",
            "Step 260. time since epoch: 617.679. Train acc: 0.613. Train Loss: 1.642\n",
            "Step 270. time since epoch: 641.331. Train acc: 0.617. Train Loss: 1.620\n",
            "Step 280. time since epoch: 664.954. Train acc: 0.621. Train Loss: 1.599\n",
            "Step 290. time since epoch: 688.605. Train acc: 0.625. Train Loss: 1.578\n",
            "Step 300. time since epoch: 712.138. Train acc: 0.629. Train Loss: 1.559\n",
            "Step 310. time since epoch: 735.753. Train acc: 0.633. Train Loss: 1.540\n",
            "Step 320. time since epoch: 759.378. Train acc: 0.636. Train Loss: 1.522\n",
            "Step 330. time since epoch: 783.054. Train acc: 0.639. Train Loss: 1.505\n",
            "Step 340. time since epoch: 806.695. Train acc: 0.642. Train Loss: 1.489\n",
            "Step 350. time since epoch: 830.297. Train acc: 0.645. Train Loss: 1.473\n",
            "Step 360. time since epoch: 853.977. Train acc: 0.648. Train Loss: 1.459\n",
            "Step 370. time since epoch: 877.396. Train acc: 0.650. Train Loss: 1.446\n",
            "Step 380. time since epoch: 901.110. Train acc: 0.653. Train Loss: 1.432\n",
            "Step 390. time since epoch: 924.780. Train acc: 0.655. Train Loss: 1.418\n",
            "Step 400. time since epoch: 948.422. Train acc: 0.658. Train Loss: 1.406\n",
            "Step 410. time since epoch: 972.073. Train acc: 0.660. Train Loss: 1.394\n",
            "Step 420. time since epoch: 995.759. Train acc: 0.662. Train Loss: 1.382\n",
            "Step 430. time since epoch: 1019.428. Train acc: 0.664. Train Loss: 1.371\n",
            "Step 440. time since epoch: 1042.182. Train acc: 0.666. Train Loss: 1.361\n",
            "--------------------\n",
            "epoch 1, loss 1.3606, train acc 0.666, test acc 0.755, time 1173.5 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pv_table['densenet161'] = {'epoch': 1, 'loss': 1.3606, 'train_acc': 0.666, 'test_acc': 0.755}\n",
        "pv_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6BWNFCiyBk7",
        "outputId": "548a86a3-cc1b-402f-bdbe-eaca2279a9a3"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'resnet18': {'epoch': 1,\n",
              "  'loss': 1.4135,\n",
              "  'train_acc': 0.659,\n",
              "  'test_acc': 0.758},\n",
              " 'vgg16': {'epoch': 1, 'loss': 1.6052, 'train_acc': 0.552, 'test_acc': 0.711},\n",
              " 'inception_v3': {'epoch': 1,\n",
              "  'loss': 2.0168,\n",
              "  'train_acc': 0.484,\n",
              "  'test_acc': 0.636},\n",
              " 'densenet161': {'epoch': 1,\n",
              "  'loss': 1.3606,\n",
              "  'train_acc': 0.666,\n",
              "  'test_acc': 0.755}}"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(pv_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "U1P4Ra9g28Os",
        "outputId": "698be847-f0b2-4d30-abbe-a7b78d07a66c"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           resnet18   vgg16  inception_v3  densenet161\n",
              "epoch        1.0000  1.0000        1.0000       1.0000\n",
              "loss         1.4135  1.6052        2.0168       1.3606\n",
              "train_acc    0.6590  0.5520        0.4840       0.6660\n",
              "test_acc     0.7580  0.7110        0.6360       0.7550"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-913542c2-1a81-435f-8aeb-0007d4d87956\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resnet18</th>\n",
              "      <th>vgg16</th>\n",
              "      <th>inception_v3</th>\n",
              "      <th>densenet161</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loss</th>\n",
              "      <td>1.4135</td>\n",
              "      <td>1.6052</td>\n",
              "      <td>2.0168</td>\n",
              "      <td>1.3606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_acc</th>\n",
              "      <td>0.6590</td>\n",
              "      <td>0.5520</td>\n",
              "      <td>0.4840</td>\n",
              "      <td>0.6660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_acc</th>\n",
              "      <td>0.7580</td>\n",
              "      <td>0.7110</td>\n",
              "      <td>0.6360</td>\n",
              "      <td>0.7550</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-913542c2-1a81-435f-8aeb-0007d4d87956')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-913542c2-1a81-435f-8aeb-0007d4d87956 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-913542c2-1a81-435f-8aeb-0007d4d87956');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb5bb8a3-5058-4c66-b731-de0c09919315\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb5bb8a3-5058-4c66-b731-de0c09919315')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb5bb8a3-5058-4c66-b731-de0c09919315 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"resnet18\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33597851493808345,\n        \"min\": 0.659,\n        \"max\": 1.4135,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.4135,\n          0.758,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vgg16\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4640938231291887,\n        \"min\": 0.552,\n        \"max\": 1.6052,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.6052,\n          0.711,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inception_v3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6899168259048816,\n        \"min\": 0.484,\n        \"max\": 2.0168,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2.0168,\n          0.636,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"densenet161\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3107457267070083,\n        \"min\": 0.666,\n        \"max\": 1.3606,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.3606,\n          0.755,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "наилучшую точность показали 2 архитектуры - resnet18 и densenet161.  \n",
        "при этом время обучения resnet18 меньше чем densenet161 в 3.3 раза"
      ],
      "metadata": {
        "id": "smpvkIsP3ZXN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sBDNsiuQ3y23"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}